<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>@font-face {
  font-family: octicons-link;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

body {
    width: 980px;
    margin-right: auto;
    margin-left: auto;
    color:#333;
    background:#fff;
}

body .markdown-body {
    padding: 45px;
    word-wrap: break-word;
}

.markdown-body .octicon-link:before {
  font: normal normal normal 16px/1 octicons-link;
  display: inline-block;
  text-decoration: none;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  content: '\f05c';
  vertical-align: middle;
}

.markdown-body .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #1b1f23;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #24292e;
  line-height: 1.5;
  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;
  font-size: 16px;
  line-height: 1.5;
  word-wrap: break-word;
}

.markdown-body .pl-c {
  color: #6a737d;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: #005cc5;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: #6f42c1;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
  color: #24292e;
}

.markdown-body .pl-ent {
  color: #22863a;
}

.markdown-body .pl-k {
  color: #d73a49;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
  color: #032f62;
}

.markdown-body .pl-smw,
.markdown-body .pl-v {
  color: #e36209;
}

.markdown-body .pl-bu {
  color: #b31d28;
}

.markdown-body .pl-ii {
  background-color: #b31d28;
  color: #fafbfc;
}

.markdown-body .pl-c2 {
  background-color: #d73a49;
  color: #fafbfc;
}

.markdown-body .pl-c2:before {
  content: "^M";
}

.markdown-body .pl-sr .pl-cce {
  color: #22863a;
  font-weight: 700;
}

.markdown-body .pl-ml {
  color: #735c0f;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  color: #005cc5;
  font-weight: 700;
}

.markdown-body .pl-mi {
  color: #24292e;
  font-style: italic;
}

.markdown-body .pl-mb {
  color: #24292e;
  font-weight: 700;
}

.markdown-body .pl-md {
  background-color: #ffeef0;
  color: #b31d28;
}

.markdown-body .pl-mi1 {
  background-color: #f0fff4;
  color: #22863a;
}

.markdown-body .pl-mc {
  background-color: #ffebda;
  color: #e36209;
}

.markdown-body .pl-mi2 {
  background-color: #005cc5;
  color: #f6f8fa;
}

.markdown-body .pl-mdr {
  color: #6f42c1;
  font-weight: 700;
}

.markdown-body .pl-ba {
  color: #586069;
}

.markdown-body .pl-sg {
  color: #959da5;
}

.markdown-body .pl-corl {
  color: #032f62;
  text-decoration: underline;
}

.markdown-body details {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body a {
  background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline-width: 0;
}

.markdown-body strong {
  font-weight: inherit;
  font-weight: bolder;
}

.markdown-body h1 {
  font-size: 2em;
  margin: .67em 0;
}

.markdown-body img {
  border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

.markdown-body hr {
  box-sizing: content-box;
  height: 0;
  overflow: visible;
}

.markdown-body input {
  font: inherit;
  margin: 0;
}

.markdown-body input {
  overflow: visible;
}

.markdown-body [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body * {
  box-sizing: border-box;
}

.markdown-body input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body a {
  color: #0366d6;
  text-decoration: none;
}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body strong {
  font-weight: 600;
}

.markdown-body hr {
  background: transparent;
  border: 0;
  border-bottom: 1px solid #dfe2e5;
  height: 0;
  margin: 15px 0;
  overflow: hidden;
}

.markdown-body hr:before {
  content: "";
  display: table;
}

.markdown-body hr:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body h1 {
  font-size: 32px;
}

.markdown-body h1,
.markdown-body h2 {
  font-weight: 600;
}

.markdown-body h2 {
  font-size: 24px;
}

.markdown-body h3 {
  font-size: 20px;
}

.markdown-body h3,
.markdown-body h4 {
  font-weight: 600;
}

.markdown-body h4 {
  font-size: 16px;
}

.markdown-body h5 {
  font-size: 14px;
}

.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
}

.markdown-body h6 {
  font-size: 12px;
}

.markdown-body p {
  margin-bottom: 10px;
  margin-top: 0;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ol,
.markdown-body ul {
  margin-bottom: 0;
  margin-top: 0;
  padding-left: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ol ol ol,
.markdown-body ol ul ol,
.markdown-body ul ol ol,
.markdown-body ul ul ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body input::-webkit-inner-spin-button,
.markdown-body input::-webkit-outer-spin-button {
  -webkit-appearance: none;
  appearance: none;
  margin: 0;
}

.markdown-body .border {
  border: 1px solid #e1e4e8!important;
}

.markdown-body .border-0 {
  border: 0!important;
}

.markdown-body .border-bottom {
  border-bottom: 1px solid #e1e4e8!important;
}

.markdown-body .rounded-1 {
  border-radius: 3px!important;
}

.markdown-body .bg-white {
  background-color: #fff!important;
}

.markdown-body .bg-gray-light {
  background-color: #fafbfc!important;
}

.markdown-body .text-gray-light {
  color: #6a737d!important;
}

.markdown-body .mb-0 {
  margin-bottom: 0!important;
}

.markdown-body .my-2 {
  margin-bottom: 8px!important;
  margin-top: 8px!important;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .py-0 {
  padding-bottom: 0!important;
  padding-top: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .py-2 {
  padding-bottom: 8px!important;
  padding-top: 8px!important;
}

.markdown-body .pl-3,
.markdown-body .px-3 {
  padding-left: 16px!important;
}

.markdown-body .px-3 {
  padding-right: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .f6 {
  font-size: 12px!important;
}

.markdown-body .lh-condensed {
  line-height: 1.25!important;
}

.markdown-body .text-bold {
  font-weight: 600!important;
}

.markdown-body:before {
  content: "";
  display: table;
}

.markdown-body:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body>:first-child {
  margin-top: 0!important;
}

.markdown-body>:last-child {
  margin-bottom: 0!important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body blockquote,
.markdown-body dl,
.markdown-body ol,
.markdown-body p,
.markdown-body pre,
.markdown-body table,
.markdown-body ul {
  margin-bottom: 16px;
  margin-top: 0;
}

.markdown-body hr {
  background-color: #e1e4e8;
  border: 0;
  height: .25em;
  margin: 24px 0;
  padding: 0;
}

.markdown-body blockquote {
  border-left: .25em solid #dfe2e5;
  color: #6a737d;
  padding: 0 1em;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #c6cbd1;
  border-bottom-color: #959da5;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #959da5;
  color: #444d56;
  display: inline-block;
  font-size: 11px;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
  line-height: 1.25;
  margin-bottom: 16px;
  margin-top: 24px;
}

.markdown-body h1 {
  font-size: 2em;
}

.markdown-body h1,
.markdown-body h2 {
  border-bottom: 1px solid #eaecef;
  padding-bottom: .3em;
}

.markdown-body h2 {
  font-size: 1.5em;
}

.markdown-body h3 {
  font-size: 1.25em;
}

.markdown-body h4 {
  font-size: 1em;
}

.markdown-body h5 {
  font-size: .875em;
}

.markdown-body h6 {
  color: #6a737d;
  font-size: .85em;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ol ul,
.markdown-body ul ol,
.markdown-body ul ul {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body li {
  word-wrap: break-all;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
  margin-top: 16px;
  padding: 0;
}

.markdown-body dl dd {
  margin-bottom: 16px;
  padding: 0 16px;
}

.markdown-body table {
  display: block;
  overflow: auto;
  width: 100%;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table td,
.markdown-body table th {
  border: 1px solid #dfe2e5;
  padding: 6px 13px;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #c6cbd1;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f6f8fa;
}

.markdown-body img {
  background-color: #fff;
  box-sizing: content-box;
  max-width: 100%;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body code {
  background-color: rgba(27,31,35,.05);
  border-radius: 3px;
  font-size: 85%;
  margin: 0;
  padding: .2em .4em;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre>code {
  background: transparent;
  border: 0;
  font-size: 100%;
  margin: 0;
  padding: 0;
  white-space: pre;
  word-break: normal;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  background-color: #f6f8fa;
  border-radius: 3px;
  font-size: 85%;
  line-height: 1.45;
  overflow: auto;
  padding: 16px;
}

.markdown-body pre code {
  background-color: transparent;
  border: 0;
  display: inline;
  line-height: inherit;
  margin: 0;
  max-width: auto;
  overflow: visible;
  padding: 0;
  word-wrap: normal;
}

.markdown-body .commit-tease-sha {
  color: #444d56;
  display: inline-block;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 90%;
}

.markdown-body .blob-wrapper {
  border-bottom-left-radius: 3px;
  border-bottom-right-radius: 3px;
  overflow-x: auto;
  overflow-y: hidden;
}

.markdown-body .blob-wrapper-embedded {
  max-height: 240px;
  overflow-y: auto;
}

.markdown-body .blob-num {
  -moz-user-select: none;
  -ms-user-select: none;
  -webkit-user-select: none;
  color: rgba(27,31,35,.3);
  cursor: pointer;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  line-height: 20px;
  min-width: 50px;
  padding-left: 10px;
  padding-right: 10px;
  text-align: right;
  user-select: none;
  vertical-align: top;
  white-space: nowrap;
  width: 1%;
}

.markdown-body .blob-num:hover {
  color: rgba(27,31,35,.6);
}

.markdown-body .blob-num:before {
  content: attr(data-line-number);
}

.markdown-body .blob-code {
  line-height: 20px;
  padding-left: 10px;
  padding-right: 10px;
  position: relative;
  vertical-align: top;
}

.markdown-body .blob-code-inner {
  color: #24292e;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  overflow: visible;
  white-space: pre;
  word-wrap: normal;
}

.markdown-body .pl-token.active,
.markdown-body .pl-token:hover {
  background: #ffea7f;
  cursor: pointer;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #d1d5da;
  border-bottom-color: #c6cbd1;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #c6cbd1;
  color: #444d56;
  display: inline-block;
  font: 11px SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body :checked+.radio-label {
  border-color: #0366d6;
  position: relative;
  z-index: 1;
}

.markdown-body .tab-size[data-tab-size="1"] {
  -moz-tab-size: 1;
  tab-size: 1;
}

.markdown-body .tab-size[data-tab-size="2"] {
  -moz-tab-size: 2;
  tab-size: 2;
}

.markdown-body .tab-size[data-tab-size="3"] {
  -moz-tab-size: 3;
  tab-size: 3;
}

.markdown-body .tab-size[data-tab-size="4"] {
  -moz-tab-size: 4;
  tab-size: 4;
}

.markdown-body .tab-size[data-tab-size="5"] {
  -moz-tab-size: 5;
  tab-size: 5;
}

.markdown-body .tab-size[data-tab-size="6"] {
  -moz-tab-size: 6;
  tab-size: 6;
}

.markdown-body .tab-size[data-tab-size="7"] {
  -moz-tab-size: 7;
  tab-size: 7;
}

.markdown-body .tab-size[data-tab-size="8"] {
  -moz-tab-size: 8;
  tab-size: 8;
}

.markdown-body .tab-size[data-tab-size="9"] {
  -moz-tab-size: 9;
  tab-size: 9;
}

.markdown-body .tab-size[data-tab-size="10"] {
  -moz-tab-size: 10;
  tab-size: 10;
}

.markdown-body .tab-size[data-tab-size="11"] {
  -moz-tab-size: 11;
  tab-size: 11;
}

.markdown-body .tab-size[data-tab-size="12"] {
  -moz-tab-size: 12;
  tab-size: 12;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

.markdown-body hr {
  border-bottom-color: #eee;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .pl-3 {
  padding-left: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .pl-7 {
  padding-left: 48px!important;
}

.markdown-body .pl-8 {
  padding-left: 64px!important;
}

.markdown-body .pl-9 {
  padding-left: 80px!important;
}

.markdown-body .pl-10 {
  padding-left: 96px!important;
}

.markdown-body .pl-11 {
  padding-left: 112px!important;
}

.markdown-body .pl-12 {
  padding-left: 128px!important;
}
</style><title>Ensemble_leanring_ANN_tensorflow_log</title></head><body><article class="markdown-body"><h1>
<a id="user-content-ensemble-leanring-ann-tensorflow-log" class="anchor" href="#ensemble-leanring-ann-tensorflow-log" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Ensemble leanring ANN tensorflow log</h1>
<h2>
<a id="user-content-30-may" class="anchor" href="#30-may" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>30 May</h2>
<p>Have tried to construct a small ANN using the architecture as follow:</p>
<pre lang="text"><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 1023)              0         
                                                                 
 dense (Dense)               (None, 40)                40960     
                                                                 
 dense_1 (Dense)             (None, 18)                738       
                                                                 
=================================================================
Total params: 41,698
Trainable params: 41,698
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<hr>
<p>Piece of the code and settings:</p>
<pre><code>batch_size = 100

optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)

callbacks=[keras.callbacks.EarlyStopping(patience=5)]
</code></pre>
<hr>
<p>accuracy keeps being below 30%</p>
<p>with the earlystopping callback of patience of 5</p>
<h2>
<a id="user-content-31-may" class="anchor" href="#31-may" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>31 May</h2>
<p>Will have to try to use numpy type as input instead of using dataset type from tensorflow.</p>
<p>Added new HeNorm initializer to each layer, this does not help with the loss and accuracy.</p>
<p>Will try 1 cycle schedule and see what is the best learning rate</p>
<h2>
<a id="user-content-1-june" class="anchor" href="#1-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1 June</h2>
<p>Have tried the 1 cycle schedule to try to find the best learning rate, however, it seems that it stil did not solve the problem with</p>
<p>high loss and not converging. And also after checking, most of the weight has been reduced to almost 0 (really low value).</p>
<p>Thought it might be the issue with regularization, have tried to drop out the regularization.</p>
<h2>
<a id="user-content-3-june" class="anchor" href="#3-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3 June</h2>
<p>Still no improvement when training without regularization, suspect that the dataset and label has been messed up, will try to start with simple numpy array and corresponding label.</p>
<p>Simply use train_test_split to give a Train set and test set, and add another argument as validation_split=0.15/(0.15+0.70), cancel the flatten layer at the same time.</p>
<p>If this does not work, then I will start writing my own preprocessing stage instead of using the precalculated dataset.</p>
<p>Or I will export the mat data to csv.</p>
<p><strong>Update: Rewrtiting the model and cut off the input flatten layer helped with the training process, now thinking probably the l2 reugularization rate of 0.01 might be too high.</strong></p>
<hr>
<p>Piece of the code and settings:</p>
<pre><code>callbacks=[keras.callbacks.EarlyStopping(patience=50)
</code></pre>
<hr>
<h3>
<a id="user-content-updated-model-summary" class="anchor" href="#updated-model-summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>updated model summary</h3>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/my_model_wo_flatten.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/my_model_wo_flatten.png" alt="model image summary" style="max-width:100%;"></a></p>
<pre lang="text"><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 40)                40960     
                                                                 
 dense_1 (Dense)             (None, 18)                738       
                                                                 
=================================================================
Total params: 41,698
Trainable params: 41,698
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>Changing the regularization rate to 0.001, the performance was great but it would overfit.</p>
<hr>
<p>final training result:</p>
<pre><code>Epoch 153/400
197/197 [==============================] - 1s 7ms/step - loss: 0.8879 - accuracy: 0.9774 - val_loss: 1.3972 - val_accuracy: 0.7436
</code></pre>
<hr>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/img_3rd_june_1826.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/img_3rd_june_1826.png" alt="image of the loss and accuracy" style="max-width:100%;"></a></p>
<h2>
<a id="user-content-4-june" class="anchor" href="#4-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4 June</h2>
<p>Changing the regularization rate to 0.005, there is a bit performance drop, but at the same time, the overfit is getting slightly better.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/img_5_june_0837.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/img_5_june_0837.png" alt="image of the loss and accuracy when l2 regu equals 0.005" style="max-width:100%;"></a></p>
<p>Just realised that I have not let the model evaluate the test set from the first training. Will add that up later.</p>
<hr>
<p>final training result:</p>
<pre><code>Epoch 145/400
197/197 [==============================] - 1s 7ms/step - loss: 1.9614 - accuracy: 0.7593 - val_loss: 2.1619 - val_accuracy: 0.6275
43/43 [==============================] - 0s 6ms/step - loss: 2.1735 - accuracy: 0.6222
</code></pre>
<hr>
<p>It seems that the validation accuracy is just 63%, more or less the same with the test accuracy, the regularization helpped shrink the gap between
training and test from 21% to 14%, seems there should be improvment that could be done.</p>
<h2>
<a id="user-content-5-june" class="anchor" href="#5-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>5 June</h2>
<p>It seems the previous model with the l2 rete at 0.001 did a better job with the performance.</p>
<p>It could also be concluded that hte validation accuracy would match the test accuracy in most cases.</p>
<hr>
<p>Evaluation result form the previous model:</p>
<pre><code>43/43 [==============================] - 0s 5ms/step - loss: 1.3979 - accuracy: 0.7459
Out[13]: [1.397900938987732, 0.7459259033203125]
</code></pre>
<hr>
<p>Will try to drop the regularization and have another full on go to see how that goes.</p>
<h3>
<a id="user-content-result-without-regularization" class="anchor" href="#result-without-regularization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>result without regularization</h3>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_5_june_1254.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_5_june_1254.png" alt="loss of the model without regularization" style="max-width:100%;"></a></p>
<hr>
<p>Evaluation result for no regularization model:</p>
<pre><code>Epoch 85/400
197/197 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.8088 - val_accuracy: 0.8017
43/43 [==============================] - 0s 5ms/step - loss: 0.8663 - accuracy: 0.7963
</code></pre>
<hr>
<p>It seems that the model without regularization performed well enough, even though the gap between the trainning and validation accuracy
was about 20%.</p>
<p>Will try to use a customized Adam optimizer to do this model again.</p>
<h3>
<a id="user-content-result-with-self-customized-adam-optimizer" class="anchor" href="#result-with-self-customized-adam-optimizer" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>result with self customized Adam optimizer</h3>
<p><code>optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)</code></p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_customized_adam_5_June_1311.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_customized_adam_5_June_1311.png" alt="model loss and accuracy" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 81/400
197/197 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.7909 - val_accuracy: 0.8068
43/43 [==============================] - 0s 5ms/step - loss: 0.8421 - accuracy: 0.8000
</code></pre>
<hr>
<p>This result looks teeny_tiny slightly better than the previous model with default Adam optimizer. however, the accuracy keeps staying at 80%.</p>
<p>It has also been spotted that the loss for the validation keeps dropping until one point it started to rise up again, however, the accuracy seems quite stable.</p>
<p>Will try to use Relu instead of sigmoid for the hidden layer's activation function.</p>
<h3>
<a id="user-content-result-with-relu-activation-function" class="anchor" href="#result-with-relu-activation-function" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>result with relu activation function</h3>
<hr>
<pre><code>model = keras.Sequential([
    keras.layers.Dense(40, activation='relu', kernel_initializer=initalizer),        
    keras.layers.Dense(18, activation='softmax', kernel_initializer=initalizer)
])
</code></pre>
<hr>
<p>It seems that relu was not as good as sigmoid in terms of performance and training stability.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_with_relu_5_june_1327.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_with_relu_5_june_1327.png" alt="model loss and accuracy with relu" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 71/400
197/197 [==============================] - 1s 7ms/step - loss: 4.1040e-04 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.7487
43/43 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.7607
</code></pre>
<hr>
<p>However, the loss of the training could go as low as the magnitude of $$4e^{-4}$$.</p>
<p>Will switch back to sigmoid and add another feature of saving the best parameters while the validation loss is at its lowest.</p>
<h3>
<a id="user-content-small-study-on-the-model-on-matlab" class="anchor" href="#small-study-on-the-model-on-matlab" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Small study on the model on matlab</h3>
<p>The loss graph on matlab could be observed:</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/loss_of_the_matlab_model_0.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/loss_of_the_matlab_model_0.png" alt="loss of the first neural net work" style="max-width:100%;"></a></p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/function_panel_of_nn0.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/function_panel_of_nn0.png" alt="the control panel and corresponding info" style="max-width:100%;"></a></p>
<p>The test run on this network is not perfect, the accuracy on this one is not as high as 90%, it is actually 86%</p>
<hr>
<pre><code>ans =

0.8667
</code></pre>
<hr>
<h2>
<a id="user-content-6-june" class="anchor" href="#6-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>6 June</h2>
<h3>
<a id="user-content-adding-dropout-in-the-training-layer" class="anchor" href="#adding-dropout-in-the-training-layer" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Adding dropout in the training layer</h3>
<p>Since the accuracy from the model of matlab could be as high as 86.7%, there should be something that could be done to imporove the accuracy on the model we have right now.</p>
<p>Since the training accuracy could be as high as 99.9%, and that would leave a gap of 20% to the validation. This has left us with the
thought of more regularization to narrow this gap.</p>
<p>Now with the attempt to add two dropout layers during training as below:</p>
<hr>
<pre><code>model = keras.Sequential([
    keras.layers.Dropout(rate=0.2),
    keras.layers.Dense(40, activation='sigmoid', kernel_initializer=initalizer),
    keras.layers.Dropout(rate=0.2),
    keras.layers.Dense(18, activation='softmax', kernel_initializer=initalizer)
])
</code></pre>
<hr>
<p>This has come to give a fairly good training result to push the validation accuracy above 84%, really close to the matlab golden model.</p>
<hr>
<pre><code>Epoch 389/400
63/63 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.9519 - val_loss: 0.5593 - val_accuracy: 0.8424
43/43 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.8422
</code></pre>
<hr>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_with_dropout_loss_6_june.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_with_dropout_loss_6_june.png" alt="model with drop out loss" style="max-width:100%;"></a></p>
<p>This model has been saved in the project in the path:</p>
<p><code>Ensemble_rewrite/CheckPointPath/my_best_model_single_nn_6_June.h5</code></p>
<h2>
<a id="user-content-9-june" class="anchor" href="#9-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>9 June</h2>
<p><strong>Dropout rate = 0.1</strong></p>
<p>Since the dropout layer has been working quite well on this regularization, a bit of playing around on the dropout rate shall be performed.</p>
<p>Will change the dropout rate to 0.1 and see how that would.</p>
<p>With the early stopping implemented with the patience of 50. The training stopped at 169 epochs with the accuracy slightly lower 81.6%</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/my_model_with_dropout_9_june.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/my_model_with_dropout_9_june.png" alt="model loss with dropout at 0.1" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 169/400
63/63 [==============================] - 0s 8ms/step - loss: 0.0606 - accuracy: 0.9868 - val_loss: 0.6417 - val_accuracy: 0.8155
43/43 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.8193
</code></pre>
<hr>
<p>However, the accuracy on the training keeps being high of around 98.7%.</p>
<p>It seems that the dropout will shrink the gap between trainng and validation. Will try stronger dropout rate.</p>
<p><strong>Dropout rate = 0.3</strong></p>
<p>Change the dropout rate to 0.3 to see how training will perform.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_w_dropout_0_3_9_june.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_w_dropout_0_3_9_june.png" alt="model loss with dropout at 0.3" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 400/400
63/63 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8817 - val_loss: 0.4820 - val_accuracy: 0.8446
43/43 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.8422
</code></pre>
<hr>
<p>From what it seems, the training only stopped here because it runs out of epochs. The training and validation accuracy are getting really close.</p>
<p>Will give it 1000 epochs to see when it will stop and how that will turn out.</p>
<blockquote>
<p><strong>LONGER RUNS</strong></p>
</blockquote>
<p>The training stopped with the accuracy of 89.2% and 85.7% for training and validation.</p>
<p>A slight boost from previous best model.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_with_dropout_0_3_1000_epochs_9_June.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_with_dropout_0_3_1000_epochs_9_June.png" alt="model loss with dropout at 0.3 and 1000 epochs" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 467/1000
63/63 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8926 - val_loss: 0.4409 - val_accuracy: 0.8569
43/43 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.8556
</code></pre>
<hr>
<p>This looks promising, would try a value in between 0.2 and 0.3 to see how it does, assumption here is that val_loss will be slightly worse than 0.3 but slightly better than 0.2 and gap of train and val will be lying in between 0.2 and 0.3.</p>
<p>At the same time, this model has been saved as "my_best_model_single_nn_9_June.h5"</p>
<p><strong>Dropout rate = 0.25</strong></p>
<p>Change the dropout rate to 0.25 to see about the performance.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_with_dropout_0_25_9_June.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_with_dropout_0_25_9_June.png" alt="model loss with dropout at 0.25" style="max-width:100%;"></a></p>
<hr>
<pre><code>Epoch 317/1000
63/63 [==============================] - 0s 7ms/step - loss: 0.2395 - accuracy: 0.9224 - val_loss: 0.4896 - val_accuracy: 0.8577
43/43 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.8541
</code></pre>
<hr>
<p>Think this model is overall as nearly good as the last one, but this model has a bigger gap and shorter training period.</p>
<p>The tradeoff prefenrece is leaning towards the dropout rate of 0.25.</p>
<p>This model will be saved as: "my_best_model_single_nn_9_June_dropout_025.h5"</p>
<h3>
<a id="user-content-another-network-with-similar-structure-and-parameter-configuration-on-different-bin-ratio" class="anchor" href="#another-network-with-similar-structure-and-parameter-configuration-on-different-bin-ratio" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Another network with similar structure and parameter configuration on different bin-ratio</h3>
<p>Will implement another simple 3 layer ANN to be trained on the second diagonal, the accuracy should be more or less the same.</p>
<p>Had a look on the second diagonal ANN, it could perform as good as 90%:</p>
<pre><code>ans =

0.9015
</code></pre>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/matlab_2nd_diagonal.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/matlab_2nd_diagonal.png" alt="matlab panel for the 2nd diagonal" style="max-width:100%;"></a></p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/matlab_2nd_diagonal_loss.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/matlab_2nd_diagonal_loss.png" alt="matlab model loss for the 2nd diagonal" style="max-width:100%;"></a></p>
<h2>
<a id="user-content-10-june" class="anchor" href="#10-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>10 June</h2>
<p>Have tried to use the same parameters configuration for the second diagonal dataset, the implementation for this network reaches similar accuracy as the previous diagonal implementation of around 85%</p>
<hr>
<pre><code>Epoch 258/1000
63/63 [==============================] - 0s 7ms/step - loss: 0.2752 - accuracy: 0.9074 - val_loss: 0.4992 - val_accuracy: 0.8460
43/43 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.8407
</code></pre>
<hr>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_10_June.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_10_June.png" alt="model loss for the 2nd diagonal" style="max-width:100%;"></a></p>
<p>Tried to turn the l2 regularizer on to see how it will affect the training.</p>
<h3>
<a id="user-content-l2-rate--0001" class="anchor" href="#l2-rate--0001" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>l2 rate = 0.001</h3>
<hr>
<pre><code>Epoch 305/1000
63/63 [==============================] - 0s 8ms/step - loss: 1.1739 - accuracy: 0.8170 - val_loss: 1.1964 - val_accuracy: 0.8054
43/43 [==============================] - 0s 5ms/step - loss: 1.1895 - accuracy: 0.8037
</code></pre>
<hr>
<p>The gap between the training and validation has been narrowed down greatly. However, the accuracy was not as good as previous results.</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_with_l2_loss.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_with_l2_loss.png" alt="model loss for the 2nd diagonal with l2 regularization 0.001" style="max-width:100%;"></a></p>
<p>Tried to set the dropout rate to 0.2 to see how it behaves.</p>
<p><strong>(dropout 0.2 + l2 0.001)</strong></p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_dropout_plus_l2.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_dropout_plus_l2.png" alt="model loss with dropout and l2 regularizer" style="max-width:100%;"></a></p>
<p>Yet it seems that the l2 regularizer did not help in terms of performance boosting.</p>
<hr>
<pre><code>Epoch 443/1000
63/63 [==============================] - 0s 8ms/step - loss: 1.0781 - accuracy: 0.8600 - val_loss: 1.1855 - val_accuracy: 0.8177
43/43 [==============================] - 0s 5ms/step - loss: 1.1854 - accuracy: 0.8044
</code></pre>
<hr>
<p><strong>dropout 0.2</strong></p>
<p>Result without l2 regularizer</p>
<p><a href="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_dropout_wo_l2_10_June.png" target="_blank" rel="noopener noreferrer"><img src="/Users/shouyuxie/Projects_machine_learning/ensemble_learning/log_written_markdown/img/model_loss_2nd_diagonal_dropout_wo_l2_10_June.png" alt="model loss with dropout without l2 regularizer" style="max-width:100%;"></a></p>
<p>The result shows that dropout rate of 0.2 could not constrain the model as well as the previous rate of 0.25, yet the final validation performance was about the same.</p>
<hr>
<pre><code>Epoch 255/1000
63/63 [==============================] - 0s 7ms/step - loss: 0.1721 - accuracy: 0.9453 - val_loss: 0.5222 - val_accuracy: 0.8446
43/43 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.8467
</code></pre>
<hr>
<p>Will keep the dropout rate as 0.25 as before.</p>
<p><strong><em>Think it's time to move on to the ensemble model writing and the final majorvote api research.</em></strong></p>
<h2>
<a id="user-content-13-june" class="anchor" href="#13-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>13 June</h2>
<p>Start writing up for the ensemble model.</p>
<p>Got interrupted by the conference preparation and admin stuff for the conference.</p>
<h2>
<a id="user-content-resumed-on-17-june" class="anchor" href="#resumed-on-17-june" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resumed on 17 June</h2>
<p>Have made a subclassing model for the small ANN since each one has the same structure and model.</p>
<div class="highlight highlight-source-python"><pre><span class="pl-k">class</span> <span class="pl-v">ANN_simple_model</span>(<span class="pl-s1">keras</span>.<span class="pl-s1">model</span>):
    ...</pre></div>
<p>Tried to have a run, but was tossed the error like this:</p>
<pre lang="Text"><code>Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models,
</code></pre>
<p>This is because the model was not a standard keras model built using Sequantial or Functional API, so older h5 file was not supported on this.</p>
<p>I have changed the way it saves the model by changing it into a path instead of a single file. Everything will be saved in the folder.</p>
<p>List goes as:</p>
<ul>
<li>assets/</li>
<li>keras_metadata.pb</li>
<li>saved_model.pb</li>
<li>variables/</li>
</ul>
<p>According to Tensorflow.org:</p>
<p><code>The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb.  The weights are saved in the variables/ directory.</code></p>
</article></body></html>